\chapter{Data Cleaning and Preprocessing}

Data cleaning and preprocessing play a pivotal role in big data analysis, particularly in the context of maritime shipping.
As the volume and complexity of data continue to grow, ensuring data quality and reliability becomes crucial. Data cleaning involves identifying and rectifying inconsistencies, errors, and missing values, while preprocessing involves transforming raw data into a suitable format for analysis.
These steps are vital for improving the accuracy and effectiveness of subsequent analysis techniques, such as predictive modeling or pattern recognition. By meticulously cleaning and preprocessing the data, this research ensures the reliability and integrity of the findings, enabling more accurate insights into vessel characteristics, operational efficiency, and decision-making processes in the maritime shipping industry.

The combination of AIS signals dataset and IHS vessel specification data enables the processing of vessel signals from the year 2022, leading to the creation of trade flows for various vessel segments.
The removal of duplicate or erroneous vessel position data is of utmost importance in this process.
By ensuring the accuracy and reliability of the vessel position data,
the subsequent trade flow analysis can provide valuable insights into the movement of different types of vessels, their routes, and the flow of goods across various segments of the maritime shipping industry.

\input{pages/chapters/dataCleaning/tradeflow.tex}
